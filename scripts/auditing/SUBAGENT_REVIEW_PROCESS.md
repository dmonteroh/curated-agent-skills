# Parallel Subagent Skill Review Process

This document describes the repeatable workflow for running **parallelized subagent reviews** of skills against `scripts/auditing/SKILL_REVIEW_CHECKLIST.md` using the project runner.

## Goals

- Review many skills quickly and consistently.
- Keep reviews **independent** (no cross-skill dependencies inside skill definitions).
- Produce direct, auditable updates with per-skill logs.

## Inputs

- `scripts/auditing/SKILL_REVIEW_CHECKLIST.md`
- One or more skill entry points: `<skill>/SKILL.md`
- Optional: shared references (e.g., `scripts/auditing/resources/agent_skills_pdf.txt`)

## Workflow Overview

1. **Select a batch** of skills to review (default batch size is 10).
2. **Spawn subagents in parallel** (one per skill) in workspace-write mode.
3. Each subagent:
   - reads `scripts/auditing/SKILL_REVIEW_CHECKLIST.md`
   - reads the target `<skill>/SKILL.md`
   - applies changes under that skill directory only
   - writes results to `scripts/auditing/logs/<skill>.log`
4. Trigger-case generator step (auto, when missing):
   - runner creates `scripts/auditing/trigger-cases/<skill>.md`
5. Controller (you or main agent):
   - checks success/failure summary from the runner
   - runs trigger-test subagents against `scripts/auditing/trigger-cases/<skill>.md`
   - optionally runs `scripts/audit_skills.py` for post-run verification

## Runner Commands

```bash
./scripts/auditing/run_parallel_skill_reviews.sh

# Narrow scope
./scripts/auditing/run_parallel_skill_reviews.sh --skill python --skill testing

# Custom concurrency
./scripts/auditing/run_parallel_skill_reviews.sh --batch-size 4

# Validate after changes
./scripts/auditing/run_parallel_skill_reviews.sh --audit-after

# Enforce trigger-cases presence for every selected skill
./scripts/auditing/run_parallel_skill_reviews.sh --fail-on-missing-trigger-cases

# Allow missing trigger-cases (not recommended)
./scripts/auditing/run_parallel_skill_reviews.sh --allow-missing-trigger-cases
```

## Review Process

1. Review each changed skill for:
   - skill independence (no required references to other skills)
   - checklist compliance
   - clarity + concision
2. Review logs in `scripts/auditing/logs/` for any QUESTIONS or failures.
3. Review trigger-test logs in `scripts/auditing/logs/<skill>.trigger-test.log`.
4. Run:

```bash
.venv/bin/python scripts/audit_skills.py
```

## Quality Gates

A skill update is acceptable if it:

- Adds trigger phrases and trigger tests
- Includes step-by-step instructions with outputs
- Adds decision points and pitfalls where relevant
- Defines required inputs and constraints
- Adds an output contract + reporting format
- Keeps skill content under token limits
- Preserves independence from other skills

## Notes

- If a skill is already compliant, logs should indicate no meaningful changes needed.
- For large or complex skills, split reference material into `references/` and add a short index.
- Keep subagent scopes **tight** to avoid accidental cross-file changes.
- Keep activation test prompts in `scripts/auditing/trigger-cases/`, not in `SKILL.md`.
- Missing trigger-cases are auto-generated by default.

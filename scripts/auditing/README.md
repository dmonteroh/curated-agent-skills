# Auditing Scripts

This folder contains the skill review checklist, the parallel review runner, and supporting artifacts.

## Setup: tiktoken required for token checks

Token checks require `tiktoken`. The recommended way to run the audit installs it automatically:

```bash
./scripts/audit-skills.sh
```

If you want to run the audit directly:

```bash
python3 -m venv .venv
.venv/bin/python -m pip install -r scripts/requirements-audit.txt
.venv/bin/python scripts/audit_skills.py
```

To explicitly skip token checks:

```bash
./scripts/audit-skills.sh --no-token-checks
```

## Parallel skill reviews

The parallel reviewer installs the same audit dependencies automatically and uses the repo `.venv`:

```bash
./scripts/auditing/run_parallel_skill_reviews.sh
```

Pipeline behavior:

1. Review subagent updates each selected `skills/<skill>/SKILL.md`.
2. Missing `scripts/auditing/trigger-cases/<skill>.md` files are auto-generated by the runner.
3. Trigger-test subagent runs after review for each successful skill update.
4. Trigger tests read `scripts/auditing/trigger-cases/<skill>.md` and write logs to `scripts/auditing/logs/<skill>.trigger-test.log`.

Useful options:

```bash
# Preview selected work without running subagents
./scripts/auditing/run_parallel_skill_reviews.sh --dry-run

# Run a smaller custom batch
./scripts/auditing/run_parallel_skill_reviews.sh --batch-size 4

# Target a subset
./scripts/auditing/run_parallel_skill_reviews.sh --skill python --skill testing

# Run repo audit after subagent updates
./scripts/auditing/run_parallel_skill_reviews.sh --audit-after

# Require trigger-cases files for all selected skills
./scripts/auditing/run_parallel_skill_reviews.sh --fail-on-missing-trigger-cases

# Keep old behavior and allow missing trigger-cases files
./scripts/auditing/run_parallel_skill_reviews.sh --allow-missing-trigger-cases

# List discovered skills
./scripts/auditing/run_parallel_skill_reviews.sh --list-skills
```

## What Each File Does

- `SKILL_REVIEW_CHECKLIST.md`
  - The canonical quality gate for skill content.
  - Enforces tool-style language, trigger phrases/tests, structured instructions, outputs, and reference decomposition.

- `run_parallel_skill_reviews.sh`
  - Spawns parallel subagent reviews (10 per batch by default).
  - Applies changes directly under each skill folder.
  - Spawns a second trigger-test subagent phase after successful review updates.
  - Supports targeting specific skills and dry-run planning.
  - Reports per-skill success/failure with log paths.
  - Measures reference size via `tiktoken` to decide when to split/index references.

- `resources/agent_skills_pdf.txt`
  - Extracted text from the reference PDF for offline use during reviews.

- `logs/`
  - Subagent execution logs per skill.

- `trigger-cases/`
  - Per-skill activation test prompts for trigger-test subagents.
  - Auto-generated when missing during auditing.
  - Not referenced from `SKILL.md` to avoid runtime token overhead.

## Decisions (Rationale)

### Checklist rules

- **Tool-style language**: Skills are a knowledge/method layer, not an agent persona.
- **Trigger cases + trigger tests**: Ensures activation behavior is predictable and repeatable without adding test prompts to SKILL.md.
- **Structured workflow**: Step outputs + decision points prevent ambiguous execution.
- **Reference decomposition**: Long or multi-topic references are split and indexed to keep SKILL.md concise and navigable.

### Reference indexing threshold

- Index when there are **2+ reference files**, or a single reference is **large** (roughly >1200 tokens) or clearly multi-topic.
- Token count is used instead of line count to match model context cost more closely.

### Token checks

- Token measurement is mandatory by default. Use `--no-token-checks` only when you need a fast, dependency-free run.

### Runner defaults

- Batch size defaults to `10`.
- The runner auto-discovers skills under `skills/*/SKILL.md`.
- Pass `--skill <name>` one or more times to restrict scope.
- Pass `--audit-after` to run `scripts/audit_skills.py` after subagent updates.
- Trigger tests are enabled by default; skip with `--no-trigger-tests`.
- Trigger-case files are auto-generated by default; skip with `--no-generate-trigger-cases`.
- Trigger files are read from `scripts/auditing/trigger-cases/<skill>.md`.
- Missing trigger-cases are treated as failures by default; opt out with `--allow-missing-trigger-cases`.

## Logs and Gitignore

If you add `scripts/auditing/logs/` to `.gitignore`, local tools and agents will still be able to read and use the logs; they simply wonâ€™t be committed to git.

## When to Regenerate agent_skills_pdf.txt

`agent_skills_pdf.txt` is derived from the reference PDF (Richard Hightower's article referenced below). Keep it if you want offline, deterministic access to the reference text. It can be regenerated at any time from the PDF if needed.

## References

These sources informed the checklist and review process:

```
https://medium.com/@richardhightower/agent-skills-the-universal-standard-transforming-how-ai-agents-work-fc7397406e2e
https://docs.github.com/en/copilot/concepts/agents/about-agent-skills
https://cursor.com/docs/context/skills
https://agentskills.io/what-are-skills
https://developers.openai.com/codex/skills/
```
